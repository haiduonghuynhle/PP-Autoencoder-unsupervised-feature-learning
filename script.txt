================================================================================
KỊCH BẢN VIDEO THUYẾT MINH - CSC14120 FINAL PROJECT
CUDA Autoencoder for CIFAR-10 Feature Learning
Thời lượng: 15-20 phút

LƯU Ý: Script này được viết để trình bày notebook CSC14120_Final_Report.ipynb
Mỗi phần có timing cụ thể và hướng dẫn chi tiết cho từng cell
================================================================================

TÓM TẮT CẤU TRÚC VIDEO:
-----------------------
PHẦN 1: Problem Overview (2-3 phút)
  - Cell 1-2: Giới thiệu, problem statement, motivation, dataset, architecture

PHẦN 2: Live Demonstration (5-7 phút)  
  - Cell 3-7: Project initialization, CPU baseline, GPU basic, GPU optimized v1, GPU optimized v2, SVM

PHẦN 3: Performance Analysis (5-7 phút)
  - Cell 8-11: Performance comparison, loss analysis, classification, feature extraction performance

PHẦN 4: Lessons Learned & Conclusion (3-5 phút)
  - Cell 12-15: Technical insights, challenges, conclusion và future work

TỔNG CỘNG: ~15-20 phút (17 code cells)

TIMING BREAKDOWN CHI TIẾT:
--------------------------
Phần 1 (2-3 phút):
  - Cell 1: 45 giây (setup + CIFAR-10 visualization + giới thiệu)
  - Cell 2: 90 giây (problem statement, motivation, architecture overview)
  → Tổng: ~2.25 phút

Phần 2 (5-7 phút):
  - Cell 3: 60 giây (project initialization + compilation)
  - Cell 4: 60 giây (CPU baseline - có thể skip nếu lâu)
  - Cell 5: 60 giây (GPU basic)
  - Cell 6: 60 giây (GPU optimized v1)
  - Cell 7: 60 giây (GPU optimized v2 + SVM integration)
  → Tổng: ~5 phút

Phần 3 (5-7 phút):
  - Cell 8: 90 giây (performance comparison overview - nhiều charts)
  - Cell 9: 60 giây (training loss analysis)
  - Cell 10: 90 giây (classification performance - nhiều charts)
  - Cell 11: 60 giây (feature extraction và SVM training performance)
  → Tổng: ~5 phút

Phần 4 (3-5 phút):
  - Cell 12: 60 giây (key technical insights)
  - Cell 13: 90 giây (major challenges và solutions)
  - Cell 14-15: 90 giây (conclusion, future work, summary)
  → Tổng: ~4 phút

================================================================================

PHẦN 1: PROBLEM OVERVIEW AND APPROACH (2-3 phút)
=================================================

[Cell 1: Setup, CIFAR-10 Visualization và Introduction - 45 giây]
"Chào thầy, em là Hải Dương. Hôm nay em xin trình bày về đồ án cuối kỳ môn Lập trình Song song.

Đồ án này tập trung vào việc học biểu diễn đặc trưng không giám sát bằng Auto Encoder 
để phân loại ảnh trên bộ dữ liệu CIFAR-10.

Bây giờ em sẽ chạy cell setup để cài đặt dependency và tải dữ liệu CIFAR-10.
[Chạy cell]

CIFAR-10 là bộ dữ liệu benchmark phổ biến trong computer vision:
- Kích thước ảnh: 32x32 pixels RGB
- Có 10 class: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck
- 50.000 ảnh training và 10.000 ảnh test

[Chỉ vào visualization]
Đây là các mẫu ảnh từ mỗi class trong CIFAR-10."

[Cell 2: Problem Statement, Motivation và Architecture - 90 giây]
"Vấn đề chính của đồ án này là làm sao để tự động khám phá các biểu diễn tốt của dữ liệu 
mà không cần nhãn trong giai đoạn học đặc trưng.

Chúng em thực hiện theo 2 giai đoạn:
- Giai đoạn 1: Học đặc trưng không giám sát, huấn luyện Auto Encoder để tái tạo ảnh CIFAR-10
- Giai đoạn 2: Phân loại có giám sát, trích xuất đặc trưng và huấn luyện SVM Classifier

Về Motivation thì chúng em đặt ra câu hỏi: Tại sao cần có GPU?

Việc huấn luyện mạng Neural trên CPU cực kỳ chậm do:
- Số lượng lớn các phép toán ma trận trong Convolution
- Thực thi tuần tự giới hạn throughput
- Bộ dữ liệu lớn với hơn 50.000 ảnh training

Song song hóa trên GPU có thể đạt được tốc độ nhanh hơn 20 lần nhờ:
- Tính toán song song trên hàng nghìn CUDA Core
- Tối ưu pattern truy cập bộ nhớ
- Kernel fusion để giảm yêu cầu băng thông bộ nhớ

Kiến trúc Auto Encoder chúng em bao gồm:
- Encoder: Nén ảnh 32x32x3 xuống Latent Representation 8x8x128 là 8192 chiều
- Decoder: Tái tạo ảnh gốc từ Latent Representation

Encoder có 2 lớp Convolution với Max Pooling để giảm kích thước.
Decoder có 2 lớp Convolution với Upsampling để tăng kích thước trở lại.

Tổng cộng có khoảng 751.875 tham số cần huấn luyện."


PHẦN 2: LIVE DEMONSTRATION OF RUNNING CODE (5-7 phút)
======================================================

[Cell 3: Project Initialization và Compilation - 60 giây]
"Phần 2: Live Demonstration

Bây giờ em sẽ chạy code thực tế. Đầu tiên là khởi tạo project và compile code CUDA.
[Chạy cell - git clone, download data, compilation]

Chúng em compile các file .cu và .cpp với NVCC và g++:
- Kiến trúc GPU được chỉ định: SM75 cho T4, SM80 cho A100
- Link với các thư viện cần thiết như cuDNN, cuBLAS"

[Cell 4: CPU Baseline Training - 60 giây]
"Để có baseline so sánh, chúng em bắt đầu với Implementation trên CPU, có thể mất một chút thời gian.
[Chạy cell - có thể skip nếu lâu]

CPU baseline cho thấy với 2% dataset để test nhanh:
- Thời gian training mỗi epoch khoảng 17 phút
- Tổng thời gian training 20 epoch khoảng 5,7 giờ
- Loss giảm từ khoảng 0,12 xuống 0,03 sau 20 epoch
- Memory usage là khoảng 285 MB

Chúng em dùng nó làm baseline so sánh với phiên bản GPU.
Chúng ta thấy rằng training trên CPU rất chậm, đặc biệt với full dataset."

[Cell 5: GPU Basic Implementation - 60 giây]
"Tiếp theo là phiên bản GPU cơ bản - Port toàn bộ code từ CPU lên GPU.
[Chạy cell hoặc giải thích]

Trong phiên bản này:
- Mỗi thread xử lý một output pixel cho convolution
- Sử dụng global memory cho tất cả các thao tác
- Kernel đơn giản cho ReLU, Max Pooling, Upsampling
- Parallelization strategy: Map Operations to GPU Threads

[Chỉ vào code nếu có thể] Đây là cách chúng em Map Convolution Operations:
- Mỗi Thread Block xử lý một vùng của Output
- Threads trong Block hợp tác load Input Data

Kết quả:
- Thời gian training giảm xuống còn khoảng 95 giây mỗi Epoch
- Tổng thời gian là khoảng 32 phút cho 20 Epoch
- Tốc độ nhanh hơn 10.8 lần so với CPU
- Memory usage khoảng hơn 800MB, tăng do GPU Memory Allocation

Đây là Improvement đầu tiên, chứng tỏ GPU Parallelization hiệu quả."

[Cell 6: GPU Optimized Version 1 - 60 giây]
"Phiên bản tối ưu đầu tiên tập trung vào tối ưu bộ nhớ với Shared Memory Tiling.
[Chạy cell hoặc giải thích]

Tối ưu hóa chính trong Version 1:

1. Shared Memory Tiling:
   - Load input tiles vào shared memory để giảm global memory access
   - Reuse loaded data across multiple threads trong cùng một block
   - Giảm memory bandwidth requirement đáng kể

2. Memory Coalescing:
   - Đảm bảo threads trong warp truy cập consecutive memory addresses
   - Reorganize Data Access Patterns để maximize bandwidth

3. Pinned Memory:
   - Sử dụng cudaMallocHost cho faster Host-to-Device Transfer
   - Cho phép Asynchronous Memory Transfer

[Chỉ vào code nếu có thể] Đây là cách implement Shared Memory Tiling trong Convolution Kernel.

Kết quả với 2% dataset:
- Thời gian training giảm xuống còn khoảng 49 đến 50 giây mỗi epoch
- Tổng thời gian khoảng 17 phút cho 20 epoch
- Speedup lên khoảng 20,7 lần so với CPU
- Incremental speedup khoảng 1,9 lần so với GPU Basic
- Memory usage hơn 800MB, không đổi

Từ đó ta thấy Shared Memory Optimization mang lại improvement đáng kể."

[Cell 7: GPU Optimized Version 2 và SVM Integration - 60 giây]
"Phiên bản tối ưu thứ 2 tập trung vào các kỹ thuật nâng cao hơn.
[Chạy cell hoặc giải thích]

Tối ưu hóa trong Version 2:

1. Kernel Fusion:
   - Kết hợp Conv, ReLU và Bias vào một kernel duy nhất
   - Loại bỏ Intermediate Global Memory Write/Read
   - Giảm Memory Bandwidth Requirements và tăng Arithmetic Intensity

2. Vectorized Memory Access:
   - Sử dụng float4 để load/store 4 floats cùng lúc
   - Better Memory Bandwidth Utilization
   - Đặc biệt hiệu quả khi Processing Channels hoặc Batch Dimensions

3. CUDA Streams:
   - Overlap Computation và Memory Transfer
   - Process batch tiếp theo trong khi batch hiện tại đang training
   - Hide Transfer Latency

4. Memory Pool:
   - Reuse Buffers thay vì Allocate/Free liên tục
   - Eliminate Repeated CUDA Malloc/CUDA Free Overhead

[Chỉ vào code nếu có thể] Kernel Fusion giúp giảm số lần truy cập Global Memory.

Kết quả:
- Thời gian training giảm xuống còn khoảng 34-35 giây mỗi epoch
- Tổng thời gian khoảng 12 phút cho 20 epoch
- Speedup lên khoảng 29,7 lần so với CPU
- Incremental speedup lên khoảng 1,44 lần so với GPU Optimization Version 1
- Memory usage vẫn là hơn 800 MB

Với full dataset thì thời gian training sẽ giảm từ hàng giờ xuống còn vài phút.
Ta thấy nếu mà áp dụng với full dataset thì thời gian training sẽ giảm rất nhiều, rất đáng kể.

Sau khi huấn luyện Auto Encoder, chúng em trích xuất Features từ Encoder và huấn luyện SVM.
[Chạy cell feature extraction và SVM training]

Quá trình này:
- Load trained Encoder Weights
- Chạy forward pass chỉ với Encoder, không có Decoder
- Trích xuất 8192-dimensional features cho mỗi ảnh
- Thời gian khoảng 20 giây cho 60.000 ảnh (50.000 ảnh train và 10.000 ảnh test)

Sử dụng cuML SVM với:
- Kernel: RBF (Radial Basis Function)
- Hyperparameter: C = 10, Gamma = Auto
- Training trên 50.000 Feature từ Training Set
- Test trên 10.000 Feature từ Test Set"


PHẦN 3: PERFORMANCE RESULTS AND ANALYSIS (5-7 phút)
=====================================================

[Cell 8: Performance Comparison Overview - 90 giây]
"Bây giờ em sẽ trình bày phân tích về kết quả performance.
[Chỉ vào comprehensive performance visualization - có 6 subplots]

[Pause 3 giây để audience nhìn toàn bộ visualization]

Bảng so sánh performance:
- CPU Baseline: khoảng 1000 giây mỗi epoch và tổng cộng là khoảng 5,7 giờ
- GPU Basic: khoảng 95 giây một epoch, khoảng 32 phút tổng cộng, speedup lên khoảng 10,8 lần so với CPU
- GPU Optimization v1: thời gian khoảng 50 giây mỗi epoch, tổng cộng khoảng 16,6 phút, speedup khoảng 20,7 lần
- GPU Optimization v2: khoảng 35 giây mỗi epoch, tổng cộng 11,6 phút, speedup 29,7 lần

[Chỉ vào chart 1 - Training Time per Epoch - pause 2 giây]
Biểu đồ này cho thấy sự cải thiện rõ rệt qua từng phiên bản.
Thời gian giảm từ 1000 giây xuống còn khoảng 35 giây, tức là gần 30 lần nhanh hơn.

[Chỉ vào chart 2 - Cumulative Speedup - pause 2 giây]
Đường speedup cho thấy tốc độ tăng dần theo từng optimization.
Chúng em đã vượt mục tiêu 20 lần và đã gần 30 lần speedup.

[Chỉ vào chart 3 - Incremental Speedup - pause 2 giây]
Incremental speedup cho thấy mỗi optimization step đều có đóng góp:
- 10,8 lần: Parallelization là improvement lớn nhất
- GPU Optimization v1: 1,91 lần, áp dụng Shared Memory Optimization
- GPU Optimization v2: 1,44 lần, áp dụng Kernel Fusion và Advanced Techniques

[Chỉ vào chart 4 - Total Training Time - pause 2 giây]
Tổng thời gian training giảm từ 5,7 giờ xuống 11,6 phút.

[Chỉ vào chart 5 - Memory Usage - pause 2 giây]
Memory usage tăng từ 285MB lên 814MB, nhưng đổi lại tốc độ tăng đáng kể.

[Chỉ vào chart 6 - Summary Table - pause 2 giây]
Bảng này tổng hợp tất cả các metrics quan trọng."

[Cell 9: Training Loss Analysis - 60 giây]
"Phân tích training loss curves.
[Chỉ vào loss visualization - có 2 subplots: full và zoomed]

[Pause 2 giây để audience nhìn]

[Chỉ vào chart trái - Full Loss Curves - pause 2 giây]
Loss curves cho tất cả các phase:
- CPU Baseline: Giảm từ 0,12 xuống 0,03 sau 20 epochs
- GPU Basic: Giảm từ 0,041 xuống 0,012
- GPU Optimization v1: Tương tự GPU Basic
- GPU Optimization v2: Loss curve gần như giống hệt

[Chỉ vào chart phải - Final 10 Epochs Zoomed - pause 2 giây]
Xem kỹ 10 epoch cuối cho thấy:
- Tất cả các version đều converge về cùng một mức loss
- GPU version có loss thấp hơn một chút do training với full batch size
- Convergence behavior tương tự nhau

Từ đó ta rút ra insights:
- Cả CPU và GPU đều có loss curve tương tự, chứng tỏ implementation đúng
- GPU version nhanh hơn nhưng cho kết quả tương đương về chất lượng
- Optimization không làm thay đổi model behavior, chỉ tăng tốc độ"

[Cell 10: Classification Performance - 90 giây]
"Kết quả phân loại cuối cùng.
[Chỉ vào comprehensive classification visualization - có nhiều subplots]

[Pause 3 giây để audience nhìn toàn bộ]

[Chỉ vào Confusion Matrix - CPU - pause 2 giây]
Confusion Matrix cho CPU version cho thấy:
- Overall accuracy khoảng 62-63% trên test set
- Một số class thì được phân loại tốt hơn

[Chỉ vào Confusion Matrix - GPU - pause 2 giây]
GPU version có accuracy tương đương, chứng tỏ feature học được có chất lượng tốt.

[Chỉ vào Overall Accuracy Comparison - pause 2 giây]
So sánh accuracy giữa CPU và GPU:
- Cả hai đều đạt khoảng 62-63%
- Không có sự khác biệt đáng kể, chứng tỏ GPU optimization không ảnh hưởng đến chất lượng

[Chỉ vào Per-Class Accuracy - pause 2 giây]
Per Class Accuracy Breakdown:
- Class dễ phân loại như Airplane, Ship, Automobile đạt khoảng 75-70-68%
  → Có đặc trưng rõ ràng, dễ phân biệt
- Class khó hơn như Cat, Dog, Deer thì tương tự nhau về hình dạng và texture

[Chỉ vào Best/Worst Performing Classes - pause 2 giây]
- Best là Airplane, Ship vì có background và shape đặc trưng
- Worst là Cat và Dog, nhìn tương tự nhau, khó phân biệt

[Chỉ vào Summary Statistics Table - pause 2 giây]
Bảng này tóm tắt các metrics chi tiết cho từng Class."

[Cell 11: Feature Extraction và SVM Training Performance - 60 giây]
"Performance của Feature Extraction và SVM Training.
[Chỉ vào pipeline performance visualization - pie chart và timeline]

[Pause 2 giây để audience nhìn]

[Chỉ vào Pie Chart - Pipeline Time Distribution - pause 2 giây]
Phân bổ thời gian trong Pipeline:
- Feature Extraction chiếm phần lớn thời gian: 20 giây cho 60K ảnh
- SVM Training nhanh hơn: khoảng 5-10 giây
- Data Loading: Minimal Overhead

[Chỉ vào Timeline Chart - Gantt-style - pause 2 giây]
Timeline cho thấy:
- Feature Extraction: 20 giây cho khoảng 60K ảnh
  → Rất nhanh, chỉ cần forward pass, không cần backward
  → Batch processing giúp tận dụng GPU hiệu quả
- SVM Training: 5-10 giây trên 50.000 features
  → cuML SVM được optimize tốt cho GPU
- Tổng thời gian pipeline dưới 30 giây

So với training time khoảng 11-12 phút, thì feature extraction rất là nhanh.
Điều này cho phép chúng ta experiment với nhiều classifiers khác nhau.

Sử dụng bộ nhớ:
- CPU: khoảng 2,1 GB
- GPU Basic: khoảng 2,1 GB
- GPU Optimization Version 1: khoảng 2,3 GB
- GPU Optimization Version 2: khoảng 2,5 GB

Memory usage tăng nhẹ nhưng đổi lại tốc độ tăng đáng kể."


PHẦN 4: KEY OPTIMIZATIONS AND LESSONS LEARNED (3-5 phút)
=========================================================

[Cell 12: Key Technical Insights - 60 giây]
"Key optimizations and lessons learned.

Từ đồ án này chúng em học được:

1. CUDA Programming:
- Shared memory là công cụ mạnh mẽ để làm giảm global memory access
- Kernel Fusion giúp giảm memory bandwidth requirement
- Memory coalescing đúng là yếu tố quan trọng cho performance

2. Deep Learning:
- Autoencoder có thể học được meaningful features mà không cần labels
- Features học được có thể dùng cho downstream tasks như classification
- Architecture design ảnh hưởng lớn đến chất lượng Feature

3. Performance Optimization:
- Profiling là bước quan trọng để identify bottlenecks
- Không phải optimization nào cũng hiệu quả, cần test và measure
- Incremental optimization approach giúp hiểu rõ impact của từng technique"

[Cell 13: Major Challenges and Solutions - 90 giây]
"Thách thức chính và cách giải quyết:

Challenge 1: Memory Management
- Vấn đề: Quản lý Memory trên GPU phức tạp, dễ gây thất thoát bộ nhớ
- Giải pháp: Sử dụng RAII Pattern, Memory Pool để reuse buffers
- Bài học: Memory Management chính xác là nền tảng cho Stable Code

Challenge 2: Correctness Verification
- Vấn đề: Đảm bảo GPU code cho kết quả giống CPU
- Giải pháp: So sánh output từng layer, sử dụng numerical checks
- Bài học: Verification là bước quan trọng trong development process

Challenge 3: Performance Tuning
- Vấn đề: Nhiều optimization techniques, không biết bắt đầu từ đâu
- Giải pháp: Profiling với nvprof để tìm bottlenecks, optimize từng phần
- Bài học: Data-driven optimization approach hiệu quả hơn guesswork"

[Cell 14-15: Conclusion và Future Work - 90 giây]
"Tóm tắt kết quả chính của đồ án:

✓ Đạt được speedup 29,7 lần so với CPU baseline
✓ Training time giảm từ 5,7 giờ xuống còn 11,6 phút
✓ Classification Accuracy đạt khoảng 62-63%
✓ Feature Extraction nhanh, chỉ khoảng 20 giây cho 60.000 ảnh
✓ Tất cả optimization đều maintain correctness

Hạn chế và thách thức:
- Accuracy có thể cải thiện thêm với architecture lớn hơn hoặc deeper network
- Chưa thử Mixed Precision Training FP16 để tăng tốc thêm
- Có thể optimize thêm với cuDNN Kernel thay vì Custom Kernel
- Memory usage tăng từ 285MB lên 814MB, có thể chấp nhận được

Hướng phát triển:

1. Cải thiện Architecture:
   - Có thể thử ResNet-based Autoencoder để học feature tốt hơn
   - Sử dụng Attention Mechanism để capture spatial relationship
   - Variational Autoencoder cho better latent space

2. Classification Improvement:
   - Sử dụng Neural Network Classifier thay cho SVM cho end-to-end fine-tuning
   - Ensemble Methods kết hợp nhiều Autoencoder features
   - Data Augmentation trong Training

3. Optimization Improvement:
   - Sử dụng Mixed Precision Training
   - Gradient checkpointing để giảm memory
   - Distributed training cho larger datasets
   - Profiling tools như Nsight Compute

4. Applications:
   - Thử nghiệm với datasets khác như CIFAR-100, ImageNet Subset
   - Transfer Learning với pre-trained Features
   - Hoặc là những downstream tasks khác như Object Detection, Segmentation"


================================================================================
GHI CHÚ CHO NGƯỜI THUYẾT TRÌNH:
================================================================================

1. TIMING:
   - Phần 1: 2-3 phút (không quá chi tiết, tập trung vào overview)
   - Phần 2: 5-7 phút (chạy code thực tế, giải thích ngắn gọn)
   - Phần 3: 5-7 phút (phân tích kết quả, chỉ vào charts)
   - Phần 4: 3-5 phút (tổng kết, lessons learned)
   - Tổng: ~15-20 phút

2. KHI CHẠY CODE:
   - Nếu cell chạy lâu, có thể skip và giải thích kết quả
   - Chuẩn bị screenshots của kết quả để show nếu cần
   - Highlight các số liệu quan trọng (speedup, accuracy, time)
   - Có thể pre-run các cells trước khi record

3. KHI CHỈ VÀO CHARTS:
   - Dừng lại 2-3 giây để audience nhìn
   - Giải thích ý nghĩa của chart trước khi đọc số liệu
   - So sánh giữa các phiên bản
   - Đọc số liệu cụ thể từ charts, không chỉ nói chung chung

4. TONE:
   - Tự tin nhưng không quá nhanh
   - Pause ở các điểm quan trọng (sau khi nói số liệu lớn)
   - Nhấn mạnh các achievements chính (29,7x speedup, vượt mục tiêu)
   - Enthusiasm khi nói về improvements
   - Giữ cách xưng "em" với thầy (phù hợp với context presentation)

5. BACKUP PLAN:
   - Nếu code không chạy được, có thể show screenshots của kết quả
   - Chuẩn bị slide backup với key numbers và charts
   - Practice trước để đảm bảo timing chính xác
   - Có thể record từng phần riêng và edit sau

6. CELL-SPECIFIC NOTES:
   - Cell 1 (Setup): Có thể skip nếu đã chạy trước, chỉ giải thích
   - Cell 3-4 (Initialization & CPU): Nếu chạy lâu, có thể show log file hoặc kết quả đã có
   - Cell 5-7 (GPU implementations): Giải thích ngắn gọn, highlight key optimizations
   - Cell 8-11 (Performance analysis): Pause để audience nhìn, giải thích từng chart, đọc số liệu cụ thể
   - Cell 12-15 (Lessons & Conclusion): Tổng kết, nhấn mạnh achievements chính

7. KEY NUMBERS TO HIGHLIGHT:
   - Speedup: 29,7 lần (vượt mục tiêu 20x) - nhấn mạnh nhiều lần
   - Training time: 11,6 phút vs 5,7 giờ (với 2% data)
   - Accuracy: 62-63% (đạt mục tiêu 60-65%)
   - Feature extraction: 20 giây cho 60K ảnh
   - Memory: 814 MB (acceptable trade-off)
   - Incremental speedups: 10,8 lần, 1,91 lần, 1,44 lần

8. TRANSITIONS:
   - Giữa các phần: "Bây giờ em sẽ chuyển sang phần..."
   - Giữa các cells: "Tiếp theo, chúng ta sẽ xem..."
   - Khi chuyển từ code sang results: "Sau khi chạy, kết quả cho thấy..."

9. COMMON PHRASES:
   - "Như chúng ta có thể thấy..." (khi chỉ vào chart)
   - "Điều quan trọng là..." (khi nhấn mạnh điểm chính)
   - "Chứng tỏ rằng..." (khi giải thích ý nghĩa)
   - "So với..." (khi so sánh)
   - "Từ đó ta thấy..." (khi rút ra kết luận)

10. Q&A PREPARATION:
    - Chuẩn bị trả lời về: tại sao chọn autoencoder, tại sao không dùng cuDNN,
      trade-offs giữa speed và accuracy, cách verify correctness
    - Nếu không biết câu trả lời: "Đây là điểm tốt để nghiên cứu thêm trong tương lai"

================================================================================
END OF SCRIPT
================================================================================

